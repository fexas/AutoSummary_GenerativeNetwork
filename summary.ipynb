{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a006825",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3417a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5dfde",
   "metadata": {},
   "source": [
    "## lotka volterra and sir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9465ca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [[\"nn_prior\",\"bf\",\"dnnabc\",\"w2\"],[\"nn\",\"bf\",\"dnnabc\",\"w2\"]]\n",
    "benchmark = [\"lv\",\"sir\"]\n",
    "d_theta =[4,2]\n",
    "folder = [\"lotka_volterra\",\"SIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c9ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a1befc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluation_metric  = [\"mean_bias\",\"refined_mean_bias\",\"median_bias\",\"refined_median_bias\"]\n",
    "\n",
    "# create a new pandas dataframe with the model and according evaluation metric\n",
    "df = pd.DataFrame(columns=[\"model\",\"benchmark\"] + evaluation_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9a578f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing nn_prior for lv...\n",
      "Processing bf for lv...\n",
      "Processing dnnabc for lv...\n",
      "Processing w2 for lv...\n",
      "Processing nn for sir...\n",
      "Processing bf for sir...\n",
      "Processing dnnabc for sir...\n",
      "Processing w2 for sir...\n"
     ]
    }
   ],
   "source": [
    "for k in range(2):\n",
    "    model_name_list = model[k]\n",
    "    benchmark_name = benchmark[k]\n",
    "    folder_name = folder[k]\n",
    "\n",
    "    for model_name in model_name_list:\n",
    "        result_path = os.path.join(os.getcwd(),f\"{folder_name}\" ,\"result\", f\"{model_name}_{benchmark_name}_result1.csv\")\n",
    "\n",
    "        if os.path.exists(result_path):\n",
    "            print(f\"Processing {model_name} for {benchmark_name}...\")\n",
    "            result_df = pd.read_csv(result_path)\n",
    "\n",
    "            mean_bias = result_df[\"bias\"].mean()\n",
    "            median_bias = result_df[\"bias\"].median()\n",
    "\n",
    "            if benchmark_name == \"lv\" and (model_name == \"nn_prior\" or model_name == \"bf\"):\n",
    "                refined_mean_bias = result_df[\"refined_bias\"].mean()\n",
    "                refined_median_bias = result_df[\"refined_bias\"].median()\n",
    "                if pd.isna(mean_bias) or pd.isna(refined_mean_bias) or pd.isna(median_bias) or pd.isna(refined_median_bias):\n",
    "                    print(\"NaN found in the result\")\n",
    "                    continue\n",
    "            elif benchmark_name == \"lv\" and (model_name == \"dnnabc\" or model_name == \"w2\"):\n",
    "                refined_mean_bias = np.nan\n",
    "                refined_median_bias = np.nan\n",
    "                if pd.isna(mean_bias)  or pd.isna(median_bias):\n",
    "                    print(\"NaN found in the result\")\n",
    "                    continue\n",
    "            elif benchmark_name == \"sir\" and (model_name == \"nn\" or model_name == \"bf\"):\n",
    "                refined_mean_bias = result_df[\"refined_bias\"].mean()\n",
    "                refined_median_bias = result_df[\"refined_bias\"].median()\n",
    "                if pd.isna(mean_bias) or pd.isna(refined_mean_bias) or pd.isna(median_bias) or pd.isna(refined_median_bias):\n",
    "                    print(\"NaN found in the result\")\n",
    "                    continue\n",
    "            elif benchmark_name == \"sir\" and (model_name == \"dnnabc\" or model_name == \"w2\"):\n",
    "                refined_mean_bias = np.nan\n",
    "                refined_median_bias = np.nan\n",
    "                if pd.isna(mean_bias)  or pd.isna(median_bias):\n",
    "                    print(\"NaN found in the result\")\n",
    "                    continue\n",
    "            \n",
    "            #  create a new row in the dataframe with the model name, benchmark name, and evaluation metrics\n",
    "            row = {\n",
    "                \"model\": model_name,\n",
    "                \"benchmark\": benchmark_name,\n",
    "                \"mean_bias\": mean_bias,\n",
    "                \"refined_mean_bias\": refined_mean_bias,\n",
    "                \"median_bias\": median_bias,\n",
    "                \"refined_median_bias\": refined_median_bias\n",
    "            }\n",
    "\n",
    "            df.loc[len(df)] = row\n",
    "\n",
    "        # result_df[\"model\"] = model_name\n",
    "        # result_df[\"benchmark\"] = benchmark_name\n",
    "        # df = pd.concat([df, result_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6972f58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      model benchmark  mean_bias  refined_mean_bias  median_bias  \\\n",
      "0  nn_prior        lv   0.146893           0.018062     0.147788   \n",
      "1        bf        lv   0.166159           0.020158     0.160045   \n",
      "2    dnnabc        lv   0.376549                NaN     0.345736   \n",
      "3        w2        lv   4.229654                NaN     4.306190   \n",
      "4        nn       sir   0.074626           0.001899     0.080167   \n",
      "5        bf       sir   0.004114           0.003209     0.003668   \n",
      "6    dnnabc       sir   0.010793                NaN     0.009215   \n",
      "7        w2       sir   0.045396                NaN     0.042235   \n",
      "\n",
      "   refined_median_bias  \n",
      "0             0.009961  \n",
      "1             0.008621  \n",
      "2                  NaN  \n",
      "3                  NaN  \n",
      "4             0.001543  \n",
      "5             0.003077  \n",
      "6                  NaN  \n",
      "7                  NaN  \n"
     ]
    }
   ],
   "source": [
    "# present df with pandas\n",
    "print(df)\n",
    "# save df to csv\n",
    "df.to_csv(os.path.join(os.getcwd(), \"summary.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9f2d41",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2c7e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list =[\"nn\",\"bf\",\"dnnabc\",\"w2abc\"]\n",
    "benchmark_name = \"toy_example\"\n",
    "evaluation_metric = [\"mean_mmd\",\"refined_mean_mmd\",\"median_mmd\",\"refined_median_mmd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de03f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding nn for toy_example exists...\n",
      "mean_mmd: 0.0342724009, refined_mean_mmd: 0.013908406330000001, median_mmd: 0.0304384975, refined_median_mmd: 0.0126022475\n",
      "adding bf for toy_example exists...\n",
      "mean_mmd: 0.024483591300000003, refined_mean_mmd: 0.0170675768, median_mmd: 0.026694830500000002, refined_median_mmd: 0.015023101\n",
      "adding dnnabc for toy_example exists...\n",
      "mean_mmd: 0.12465138979999998, refined_mean_mmd: nan, median_mmd: 0.124554287, refined_median_mmd: nan\n",
      "adding w2abc for toy_example exists...\n",
      "mean_mmd: 0.1072781357, refined_mean_mmd: nan, median_mmd: 0.1094264975, refined_median_mmd: nan\n"
     ]
    }
   ],
   "source": [
    "toy_df = pd.DataFrame(columns=[\"model\",\"benchmark\"] + evaluation_metric)\n",
    "for model_name in model_list:\n",
    "    if model_name == \"nn\" or model_name == \"bf\":\n",
    "        result_path = os.path.join(os.getcwd(),f\"Toy_Example\" ,\"replicate_results\", f\"{model_name}_replicate_mmd.csv\")\n",
    "        if os.path.exists(result_path):\n",
    "            print(f\"adding {model_name} for {benchmark_name} exists...\")\n",
    "            result_df = pd.read_csv(result_path)\n",
    "            mean_mmd = result_df[\"MMD\"].mean()\n",
    "            median_mmd = result_df[\"MMD\"].median()\n",
    "            refined_mean_mmd = result_df[\"refined MMD\"].mean()\n",
    "            refined_median_mmd = result_df[\"refined MMD\"].median()\n",
    "            if pd.isna(mean_mmd) or pd.isna(refined_mean_mmd) or pd.isna(median_mmd) or pd.isna(refined_median_mmd):\n",
    "                print(\"NaN found in the result\")\n",
    "                continue\n",
    "            print(f\"mean_mmd: {mean_mmd}, refined_mean_mmd: {refined_mean_mmd}, median_mmd: {median_mmd}, refined_median_mmd: {refined_median_mmd}\")\n",
    "    else:\n",
    "        result_path = os.path.join(os.getcwd(),f\"Toy_Example\" ,\"replicate_results\", f\"{model_name}_replicate_mmd.csv\")\n",
    "        if os.path.exists(result_path):\n",
    "            print(f\"adding {model_name} for {benchmark_name} exists...\")\n",
    "            result_df = pd.read_csv(result_path)\n",
    "            mean_mmd = result_df[\"MMD\"].mean()\n",
    "            median_mmd = result_df[\"MMD\"].median()\n",
    "            refined_mean_mmd = np.nan\n",
    "            refined_median_mmd = np.nan\n",
    "            if pd.isna(mean_mmd) or pd.isna(median_mmd):\n",
    "                print(\"NaN found in the result\")\n",
    "                continue\n",
    "            print(f\"mean_mmd: {mean_mmd}, refined_mean_mmd: {refined_mean_mmd}, median_mmd: {median_mmd}, refined_median_mmd: {refined_median_mmd}\")\n",
    "    \n",
    "    row = {\n",
    "        \"model\": model_name,\n",
    "        \"benchmark\": benchmark_name,\n",
    "        \"mean_mmd\": mean_mmd,\n",
    "        \"refined_mean_mmd\": refined_mean_mmd,\n",
    "        \"median_mmd\": median_mmd,\n",
    "        \"refined_median_mmd\": refined_median_mmd\n",
    "    }\n",
    "    toy_df.loc[len(toy_df)] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e824c76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding mmd for toy_example exists...\n",
      "mean_mmd: 0.039051432000000004, refined_mean_mmd: 0.0181978509, median_mmd: 0.035105388, refined_median_mmd: 0.0175771635\n"
     ]
    }
   ],
   "source": [
    "model_name =\"mmd\"\n",
    "result_path = os.path.join(os.getcwd(),f\"Toy_Example_MMD\" ,\"replicate_results\", f\"{model_name}_replicate_mmd.csv\")\n",
    "print(f\"adding {model_name} for {benchmark_name} exists...\")\n",
    "result_df = pd.read_csv(result_path)\n",
    "mean_mmd = result_df[\"MMD\"].mean()\n",
    "median_mmd = result_df[\"MMD\"].median()\n",
    "refined_mean_mmd = result_df[\"refined MMD\"].mean()\n",
    "refined_median_mmd = result_df[\"refined MMD\"].median()\n",
    "if pd.isna(mean_mmd) or pd.isna(refined_mean_mmd) or pd.isna(median_mmd) or pd.isna(refined_median_mmd):\n",
    "    print(\"NaN found in the result\")\n",
    "print(f\"mean_mmd: {mean_mmd}, refined_mean_mmd: {refined_mean_mmd}, median_mmd: {median_mmd}, refined_median_mmd: {refined_median_mmd}\")\n",
    "\n",
    "row = {\n",
    "        \"model\": model_name,\n",
    "        \"benchmark\": benchmark_name,\n",
    "        \"mean_mmd\": mean_mmd,\n",
    "        \"refined_mean_mmd\": refined_mean_mmd,\n",
    "        \"median_mmd\": median_mmd,\n",
    "        \"refined_median_mmd\": refined_median_mmd\n",
    "    }\n",
    "\n",
    "toy_df.loc[len(toy_df)] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea2482e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model    benchmark  mean_mmd  refined_mean_mmd  median_mmd  \\\n",
      "0      nn  toy_example  0.034272          0.013908    0.030438   \n",
      "1      bf  toy_example  0.024484          0.017068    0.026695   \n",
      "2  dnnabc  toy_example  0.124651               NaN    0.124554   \n",
      "3   w2abc  toy_example  0.107278               NaN    0.109426   \n",
      "4     mmd  toy_example  0.039051          0.018198    0.035105   \n",
      "\n",
      "   refined_median_mmd  \n",
      "0            0.012602  \n",
      "1            0.015023  \n",
      "2                 NaN  \n",
      "3                 NaN  \n",
      "4            0.017577  \n"
     ]
    }
   ],
   "source": [
    "print(toy_df)\n",
    "# save toy_df to csv\n",
    "toy_df.to_csv(os.path.join(os.getcwd(), \"toy_summary.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9d905",
   "metadata": {},
   "source": [
    "## Toy Example 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1e418",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list =[\"nn\",\"bf\",\"dnnabc\",\"w2abc\"]\n",
    "benchmark_name = \"toy_example\"\n",
    "evaluation_metric = [\"mean_mmd\",\"refined_mean_mmd\",\"median_mmd\",\"refined_median_mmd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd239e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding nn for toy_example exists...\n",
      "mean_mmd: 0.041478412900000004, refined_mean_mmd: 0.022568678000000002, median_mmd: 0.034130133, refined_median_mmd: 0.01992182\n",
      "adding bf for toy_example exists...\n",
      "mean_mmd: 0.0384372845, refined_mean_mmd: 0.0330825391, median_mmd: 0.026649146999999998, refined_median_mmd: 0.0220778925\n",
      "adding dnnabc for toy_example exists...\n",
      "mean_mmd: 0.1257485265, refined_mean_mmd: nan, median_mmd: 0.1248755425, refined_median_mmd: nan\n",
      "adding w2abc for toy_example exists...\n",
      "mean_mmd: 0.0999992259, refined_mean_mmd: nan, median_mmd: 0.099835067, refined_median_mmd: nan\n"
     ]
    }
   ],
   "source": [
    "toy_df = pd.DataFrame(columns=[\"model\",\"benchmark\"] + evaluation_metric)\n",
    "for model_name in model_list:\n",
    "    if model_name == \"nn\" or model_name == \"bf\":\n",
    "        result_path = os.path.join(os.getcwd(),f\"Toy_Example_25\" ,\"replicate_results\", f\"{model_name}_replicate_mmd.csv\")\n",
    "        if os.path.exists(result_path):\n",
    "            print(f\"adding {model_name} for {benchmark_name} exists...\")\n",
    "            result_df = pd.read_csv(result_path)\n",
    "            mean_mmd = result_df[\"MMD\"].mean()\n",
    "            median_mmd = result_df[\"MMD\"].median()\n",
    "            refined_mean_mmd = result_df[\"refined MMD\"].mean()\n",
    "            refined_median_mmd = result_df[\"refined MMD\"].median()\n",
    "            if pd.isna(mean_mmd) or pd.isna(refined_mean_mmd) or pd.isna(median_mmd) or pd.isna(refined_median_mmd):\n",
    "                print(\"NaN found in the result\")\n",
    "                continue\n",
    "            print(f\"mean_mmd: {mean_mmd}, refined_mean_mmd: {refined_mean_mmd}, median_mmd: {median_mmd}, refined_median_mmd: {refined_median_mmd}\")\n",
    "    else:\n",
    "        result_path = os.path.join(os.getcwd(),f\"Toy_Example_25\" ,\"replicate_results\", f\"{model_name}_replicate_mmd.csv\")\n",
    "        if os.path.exists(result_path):\n",
    "            print(f\"adding {model_name} for {benchmark_name} exists...\")\n",
    "            result_df = pd.read_csv(result_path)\n",
    "            mean_mmd = result_df[\"MMD\"].mean()\n",
    "            median_mmd = result_df[\"MMD\"].median()\n",
    "            refined_mean_mmd = np.nan\n",
    "            refined_median_mmd = np.nan\n",
    "            if pd.isna(mean_mmd) or pd.isna(median_mmd):\n",
    "                print(\"NaN found in the result\")\n",
    "                continue\n",
    "            print(f\"mean_mmd: {mean_mmd}, refined_mean_mmd: {refined_mean_mmd}, median_mmd: {median_mmd}, refined_median_mmd: {refined_median_mmd}\")\n",
    "    \n",
    "    row = {\n",
    "        \"model\": model_name,\n",
    "        \"benchmark\": benchmark_name,\n",
    "        \"mean_mmd\": mean_mmd,\n",
    "        \"refined_mean_mmd\": refined_mean_mmd,\n",
    "        \"median_mmd\": median_mmd,\n",
    "        \"refined_median_mmd\": refined_median_mmd\n",
    "    }\n",
    "    toy_df.loc[len(toy_df)] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf762677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model    benchmark  mean_mmd  refined_mean_mmd  median_mmd  \\\n",
      "0      nn  toy_example  0.041478          0.022569    0.034130   \n",
      "1      bf  toy_example  0.038437          0.033083    0.026649   \n",
      "2  dnnabc  toy_example  0.125749               NaN    0.124876   \n",
      "3   w2abc  toy_example  0.099999               NaN    0.099835   \n",
      "\n",
      "   refined_median_mmd  \n",
      "0            0.019922  \n",
      "1            0.022078  \n",
      "2                 NaN  \n",
      "3                 NaN  \n"
     ]
    }
   ],
   "source": [
    "print(toy_df)\n",
    "# save toy_df to csv\n",
    "toy_df.to_csv(os.path.join(os.getcwd(), \"toy_25_summary.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b9febd",
   "metadata": {},
   "source": [
    "## Toy Example 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71abe2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list =[\"nn\",\"bf\",\"dnnabc\",\"w2abc\"]\n",
    "benchmark_name = \"toy_example\"\n",
    "evaluation_metric = [\"mean_mmd\",\"refined_mean_mmd\",\"median_mmd\",\"refined_median_mmd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4f48b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding nn for toy_example exists...\n",
      "mean_mmd: 0.0626268608, refined_mean_mmd: 0.0252171948, median_mmd: 0.061864151, refined_median_mmd: 0.023988831500000002\n",
      "adding bf for toy_example exists...\n",
      "mean_mmd: 0.0549567104, refined_mean_mmd: 0.034709163, median_mmd: 0.0521291755, refined_median_mmd: 0.030222181\n",
      "adding dnnabc for toy_example exists...\n",
      "mean_mmd: 0.13760090399999997, refined_mean_mmd: nan, median_mmd: 0.13663956500000002, refined_median_mmd: nan\n",
      "adding w2abc for toy_example exists...\n",
      "mean_mmd: 0.13123886599999998, refined_mean_mmd: nan, median_mmd: 0.13272292000000002, refined_median_mmd: nan\n"
     ]
    }
   ],
   "source": [
    "toy_df = pd.DataFrame(columns=[\"model\",\"benchmark\"] + evaluation_metric)\n",
    "for model_name in model_list:\n",
    "    if model_name == \"nn\" or model_name == \"bf\":\n",
    "        result_path = os.path.join(os.getcwd(),f\"Toy_Example_100\" ,\"replicate_results\", f\"{model_name}_replicate_mmd.csv\")\n",
    "        if os.path.exists(result_path):\n",
    "            print(f\"adding {model_name} for {benchmark_name} exists...\")\n",
    "            result_df = pd.read_csv(result_path)\n",
    "            mean_mmd = result_df[\"MMD\"].mean()\n",
    "            median_mmd = result_df[\"MMD\"].median()\n",
    "            refined_mean_mmd = result_df[\"refined MMD\"].mean()\n",
    "            refined_median_mmd = result_df[\"refined MMD\"].median()\n",
    "            if pd.isna(mean_mmd) or pd.isna(refined_mean_mmd) or pd.isna(median_mmd) or pd.isna(refined_median_mmd):\n",
    "                print(\"NaN found in the result\")\n",
    "                continue\n",
    "            print(f\"mean_mmd: {mean_mmd}, refined_mean_mmd: {refined_mean_mmd}, median_mmd: {median_mmd}, refined_median_mmd: {refined_median_mmd}\")\n",
    "    else:\n",
    "        result_path = os.path.join(os.getcwd(),f\"Toy_Example_100\" ,\"replicate_results\", f\"{model_name}_replicate_mmd.csv\")\n",
    "        if os.path.exists(result_path):\n",
    "            print(f\"adding {model_name} for {benchmark_name} exists...\")\n",
    "            result_df = pd.read_csv(result_path)\n",
    "            mean_mmd = result_df[\"MMD\"].mean()\n",
    "            median_mmd = result_df[\"MMD\"].median()\n",
    "            refined_mean_mmd = np.nan\n",
    "            refined_median_mmd = np.nan\n",
    "            if pd.isna(mean_mmd) or pd.isna(median_mmd):\n",
    "                print(\"NaN found in the result\")\n",
    "                continue\n",
    "            print(f\"mean_mmd: {mean_mmd}, refined_mean_mmd: {refined_mean_mmd}, median_mmd: {median_mmd}, refined_median_mmd: {refined_median_mmd}\")\n",
    "    \n",
    "    row = {\n",
    "        \"model\": model_name,\n",
    "        \"benchmark\": benchmark_name,\n",
    "        \"mean_mmd\": mean_mmd,\n",
    "        \"refined_mean_mmd\": refined_mean_mmd,\n",
    "        \"median_mmd\": median_mmd,\n",
    "        \"refined_median_mmd\": refined_median_mmd\n",
    "    }\n",
    "    toy_df.loc[len(toy_df)] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "757d9f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model    benchmark  mean_mmd  refined_mean_mmd  median_mmd  \\\n",
      "0      nn  toy_example  0.062627          0.025217    0.061864   \n",
      "1      bf  toy_example  0.054957          0.034709    0.052129   \n",
      "2  dnnabc  toy_example  0.137601               NaN    0.136640   \n",
      "3   w2abc  toy_example  0.131239               NaN    0.132723   \n",
      "\n",
      "   refined_median_mmd  \n",
      "0            0.023989  \n",
      "1            0.030222  \n",
      "2                 NaN  \n",
      "3                 NaN  \n"
     ]
    }
   ],
   "source": [
    "print(toy_df)\n",
    "# save toy_df to csv\n",
    "toy_df.to_csv(os.path.join(os.getcwd(), \"toy_100_summary.csv\"), index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef815b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math5470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
